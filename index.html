<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Exploiting SPARQL Filter Expressions for Link Pruning during Link Traversal Query processing</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" media="all"    href="styles/katex.css" />
  <meta name="citation_title" content="Exploiting SPARQL Filter Expressions for Link Pruning during Link Traversal Query processing">
  <meta name="citation_author" content="Bryan-Elliott Tam" />
  <meta name="citation_author" content="Ruben Taelman" />
  <meta name="citation_author" content="Pieter Colpaert" />
  
  <meta name="citation_publication_date" content="2023/07/14" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1 id="exploiting-sparql-filter-expressions-for-link-pruning-during-link-traversal-query-processing">Exploiting SPARQL Filter Expressions for Link Pruning during Link Traversal Query processing</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://github.com/constraintAutomaton" typeof="foaf:Person schema:Person" resource="">Bryan-Elliott Tam</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="http://www.rubensworks.net/" typeof="foaf:Person schema:Person" resource="http://www.rubensworks.net/#me">Ruben Taelman</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://pietercolpaert.be/" typeof="foaf:Person schema:Person" resource="https://pietercolpaert.be/#me">Pieter Colpaert</a></li>
  </ul>

  <ul id="affiliations">
    <li id="myaffiliation">IDLab, Department of Electronics and Information Systems, Ghent University – imec</li>
  </ul>

</header>
<!-- Hack to make our custom fonts load in print-mode -->
<!-- https://stackoverflow.com/questions/39364259/chrome-print-preview-doesnt-load-media-only-print-font-face -->
<p><span class="printfont1"> </span>
<span class="printfont2"> </span>
<span class="printfont3"> </span>
<span class="printfont4"> </span></p>

<div id="content">
  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context      -->
      <p>Linked data can be used to model all sorts of objects, which can be queried to power applications.
In some use cases like sensor data publication, the size of the data dump can become quite large.
The most popular way to query RDF data is a server-side SPARQL endpoint.
This query strategy at the current time has caused a large problem of unavailability of data.
<!-- Need         -->
Alternative strategies are to create a tradeoff between the client and 
the server by fragmenting and annotating with hypermedia descriptions the dataset.
In recent years domain-related fragmentation strategies (by date, by value and so on) 
have been created where the client has to use Link Traversal Query Processing to acces the data.
At the current time, there are no generic SPARQL ways to query the data. 
<!-- Task         -->
We propose to use a filter pushdown strategy with the SPARQL query language to prune the links that are not relevant to the query result.
<!-- Object       -->
This paper presents our strategy and early experimental results.
<!-- Findings     -->
We found that by using this strategy we have been able to drastically 
reduce the query execution time and the number of HTTP requests
needed to answer time-related queries over sensor data.
<!-- Conclusion   -->
Given the positive result of early effort, we will in the future extend our investigation with  more complex filter expressions
and more datasets and compare our results with other SPARQL interfaces.</p>

    </div>
</section>

<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Introduction</h2>

        <p><a href="https://lod-cloud.net/#diagram">In the current years, the web of linked data has grown in size</a>.
To access those data it is necessary to have an interface, the most common is the SPARQL endpoint.
When querying SPARQL endpoints, the interface takes the whole query load and delivers the results to the client,
which causes high workloads and is partially the reason that <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1007/978-3-642-41338-4_18"><a href="https://doi.org/10.1007/978-3-642-41338-4_18">historically they had a low
availability</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>.
Academics have made efforts to introduce linked data publication methods to make the client participate in the query execution,
with the aim to diminish the workloads of the server and still have fast query execution to the client <span class="references">[<a href="#ref-2">2</a>, <a href="#ref-3">3</a>]</span>.
The TREE specification is an effort in that direction <span class="references">[<a href="#ref-4">4</a>, <a href="#ref-5">5</a>]</span>,
that introduces the concept of domain-related fragmentation of large RDF datasets.
For example, in the case of periodic measurement of sensor data the fragmentation can be made on the publication date.
TREE aims to fragment datasets in a way that enables clients to easily fetch a subset of it to answer their query fully.
The data inside a fragment are bounded with constraints that are expressed using hypermedia descriptions <span class="references">[<a href="#ref-6">6</a>]</span>.
More precisely, each fragment declaratively describes the constraints of the data it contains, and links to other fragments.
Since TREE fragments are hyperlinked Linked Data documents,
clients must traverse over these documents to find data,
which makes Link Traversal Query Processing (LTQP) <span class="references">[<a href="#ref-7">7</a>]</span> a suitable technique for answering SPARQL queries over it.
LTQP typically starts with a set of seed URLs that are dereferenced.
From these dereferenced documents, links to other documents are dereferenced recursively.
So far, applications on top of TREE datasets <span class="references">[<a href="#ref-4">4</a>, <a href="#ref-5">5</a>]</span>
have resorted to custom traversal implementations to find data matching custom data needs.
Our aim in this work is to explore how to execute generic SPARQL queries over TREE datasets through LTQP.
We do not aim to extend the existing TREE specification,
but merely to introduce LTQP-specific link pruning techniques that exploit the structural properties of TREE,
similar to the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2023-SolidQuery/">exploitation of structural properties when performing LTQP over the Solid environment</a> <span class="references">[<a href="#ref-8">8</a>]</span>.
Specifically, we will make use of the SPARQL FILTER expression to prune links that match the constraints of TREE fragments.</p>

        <p>As a running example throughout this paper, we consider the publication of sensor data.
For example, the query in <a href="#example-sparql">Listing 1</a> targets the DAHCC <span class="references">[<a href="#ref-9">9</a>]</span> dataset.
We make queries to get the measure of a specific interval (the filter expression will vary in our experiment) 
and information about the sensor using a metadata file that is available online at
<a href="">https:/​/​github.com/predict-idlab/DAHCC-Sources/blob/main/instantiated_examples/_Homelab.owl</a> 
(we adapt the file by deleting the named graph and we use the metavariable<code>{:property}</code> to accommodate the dataset).</p>

        <div class="sidebysidecontainer" style="align-items: stretch !important; ">
<figure id="example-sparql" class="listing" style="padding-right: 5px; padding-left: 5px; height='100%'">
<pre><code>PREFIX sosa: &lt;http://www.w3.org/ns/sosa/&gt; 
</code><code>PREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; 
</code><code>PREFIX wgs: &lt;http://www.w3.org/2003/01/geo/wgs84_pos#&gt;
</code><code>PREFIX etsi: &lt;https://saref.etsi.org/core/&gt;
</code><code>PREFIX dahcc: &lt;https://dahcc.idlab.ugent.be/Ontology/Sensors/&gt;
</code><code>PREFIX saref: &lt;https://saref.etsi.org/core/&gt;
</code><code>
</code><code>SELECT * WHERE {
</code><code>  ?s etsi:hasTimestamp ?t.
</code><code>  ?s etsi:hasValue ?result.
</code><code>  ?s etsi:measurementMadeBy ?sensor.
</code><code>  ?sensor dahcc:analyseStateOf ?stateOf.
</code><code>  ?sensor saref:measuresProperty {:property}
</code><code>  
</code><code>  FILTER(?t=&quot;2022-01-03T10:57:54.000000&quot;^^xsd:dateTime)
</code><code>}</code></pre>
<figcaption>
              <p><span class="label">Listing 1:</span> SPARQL query to get sensor measurements and metadata</p>
            </figcaption>
</figure>

<figure id="TREE-relation-turtle-example" class="listing" style="padding-right: 5px; padding-left: 5px">
<pre><code>@prefix tree: &lt;https://w3id.org/tree#&gt; .
</code><code>@prefix sosa: &lt;http://www.w3.org/ns/sosa/&gt; .
</code><code>@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .
</code><code>@prefix ex: &lt;https://example.be/&gt; .
</code><code>@prefix etsi: &lt;https://saref.etsi.org/core/&gt;
</code><code>
</code><code>ex:node tree:relation _:b1 .
</code><code>_:b1 a  tree:GreaterThanOrEqualToRelation ;
</code><code>    tree:node ex:nextNode ;
</code><code>    tree:value &quot;2022-01-03T09:47:59.000000&quot;^^xsd:dateTime ;
</code><code>    tree:path etsi:hasTimestamp ;
</code></pre>
<figcaption>
              <p><span class="label">Listing 2:</span> In this RDF snippet can be read in natural language as in the fragment <code>ex:nextNode</code> there are data that are have the property <code>etsi:hasTimestamp</code>
that respect the constraint <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">?</mo><mi>t</mi><mo>&gt;</mo><mo>=</mo><mtext>2022-01-03T09:47:59.000000</mtext></mrow><annotation encoding="application/x-tex">?t&gt;= \text{2022-01-03T09:47:59.000000}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mclose">?</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">2022-01-03T09:47:59.000000</span></span></span></span></span>.</p>
            </figcaption>
</figure>
</div>

        <p><span class="comment" data-author="RT">If I remember correctly, you were planning a demo. As such, explicitly say that this is a demo. You’ll also need a dedicated section explaining what you will show during the demonstration. You can find inspiration in my older papers.</span></p>

        <p><span class="comment" data-author="BET">Given the time available I think the simplest would be to make a poster paper</span></p>
      </div>
</section>

  <section id="guided_link_traversal" inlist="" rel="schema:hasPart" resource="#guided_link_traversal">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Pruning links using filter expressions</h2>

        <p>Most research around LTQP has been done on query execution over Linked Open Data <span class="references">[<a href="#ref-7">7</a>]</span>.
Given the pseudo-infinite number of documents on the Web, traversing over all documents is practically infeasible.
To get a grasp on this completeness issue, different reachability criteria <span class="references">[<a href="#ref-10">10</a>]</span> were introduced
that allow certain links not to be followed based on the query that is executed.
Recently, an alternative direction was introduced <span class="references">[<a href="#ref-11">11</a>]</span>
were instead of just looking at the query to determine which links to follow,
the data publisher could <em>guide</em> the engine towards query-relevant links.
This strategy was <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2023-SolidQuery/">applied on the Solid ecosystem</a> <span class="references">[<a href="#ref-8">8</a>]</span>,
where the structural properties of Solid were exploited to prune links when traversing over Solid vaults.</p>

        <p>Our approach builds upon this concept of guided link traversal,
and similar to the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2023-SolidQuery/">Solid approach</a> <span class="references">[<a href="#ref-8">8</a>]</span> exploits the structural properties of TREE datasets to prune links.
Concretely, we interpret the hypermedia descriptions of constraints in TREE fragments as boolean equations
as shown in <a href="#TREE-relation-turtle-example">Listing 2</a>.
Upon discovery of a document, the query engine gathers the relevant triples to form the boolean expression 
representing the constraint of the next fragment and effectively pushed down the SPARQL filter expression into the engine’s dereferencing component.
After having those two boolean expressions close together they are evaluated to find the satisfiability and upon satisfaction
the IRI targeting the next fragment is added to the link queue following the concept of reachability criterium.</p>
        <figure id="results-queries" class="table table-smaller-font">

          <table>
            <thead>
              <tr>
                <th>Configuration</th>
                <th>Query</th>
                <th>QT (ms)</th>
                <th>NH</th>
                <th>NR</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>One ary 100/1000 fragments</td>
                <td>Q1/Q2/Q3/Q4</td>
                <td>X</td>
                <td>X</td>
                <td>X</td>
              </tr>
              <tr>
                <td>One ary 100/1000 fragments Filter pushdown</td>
                <td>Q4</td>
                <td>X</td>
                <td>X</td>
                <td>X</td>
              </tr>
              <tr>
                <td>One ary 100 fragments Filter pushdown</td>
                <td>Q1</td>
                <td>8,892</td>
                <td>3</td>
                <td>0</td>
              </tr>
              <tr>
                <td>One ary 100 fragments Filter pushdown</td>
                <td>Q2</td>
                <td>3,541</td>
                <td>3</td>
                <td>1</td>
              </tr>
              <tr>
                <td>One ary 100 fragments Filter pushdown</td>
                <td>Q3</td>
                <td>59,274</td>
                <td>8</td>
                <td>8,166</td>
              </tr>
              <tr>
                <td>One ary 1000 fragments Filter pushdown</td>
                <td>Q1</td>
                <td>1,171</td>
                <td>3</td>
                <td>0</td>
              </tr>
              <tr>
                <td>One ary 1000 fragments Filter pushdown</td>
                <td>Q2</td>
                <td>734</td>
                <td>3</td>
                <td>1</td>
              </tr>
              <tr>
                <td>One ary 1000 fragments Filter pushdown</td>
                <td>Q3</td>
                <td>39,987</td>
                <td>51</td>
                <td>8,166</td>
              </tr>
            </tbody>
          </table>

          <figcaption>
            <p><span class="label">Table 1:</span> Result of the query with our different configurations. <em>Qt</em> is the query execution time,
<em>NH</em> The number of HTTP request and <em>NR</em> the number of result.</p>
          </figcaption>
        </figure>

        <p>We have implemented our approach into the LTQP version of <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">Comunica</a> <span class="references">[<a href="#ref-12">12</a>]</span> at
<a href="">https:/​/​github.com/constraintAutomaton/comunica-feature-link-traversal/tree/feature/time-filtering-tree-sparqlee-implementation</a> with an associated demo available at
<a href="">https:/​/​github.com/constraintAutomaton/TREE-Solver-LTQP-demo-engine</a>.</p>

        <h2 id="experimental-results">Experimental results</h2>

        <p>To evaluate our approach, we executed four queries similar to the one in <a href="#example-sparql">Listing 1</a>.
All queries are available at <a href="">https:/​/​github.com/constraintAutomaton/How-TREE-hypermedia-can-speed-up-Link-Traversal-based-Query-Processing-queries/tree/main/content/code</a>.
These queries were executed with two configurations that will be describe below.
They were executed over the DAHCC participant 31 dataset (of 487 MB) with a timeout of two minutes.
We convert the data dump into a fragmented dataset following the TREE specification with a one-ary tree topology with 100 and 1000 nodes.</p>

        <p>In the first configuration we use a reachability criterium where the engine follow each link of the fragmented dataset.
For the second one we use our pushdown filter approach.
As shown in <a href="#results-queries">Table 1</a> no query could be answered by following every fragment. 
The reason might the size of the dataset to be processed before executing the joining and solution mapping.
For the configurations with a pushdown filter method, we see that the queries with 1000 fragments perform better than
the one with 100 fragments, particularly when the query has one or zero results. In those cases, the query execution time is almost one
order of magnitude lower with the largest number of fragments. 
With Q3 we can see that the percentage of reduction is 32%, this lowering of performance might be caused by the increase by a factor of 17
of HTTP requests. The query Q4 was not able to be answered, with both fragmentations, the cause might be because it covers a far larger range and hence requires more data to be downloaded and more processing time.</p>

      </div>
</section>

  <section id="conclusion" inlist="" rel="schema:hasPart" resource="#conclusion">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Conclusion</h2>

        <p>Our preliminary results show that our filter-based link pruning approach to LTQP over fragmented RDF documents
can be effective for significantly reducing the number of links to traverse.
This leads to a significantly lower amount of data to be downloaded, and overall query execution time to be lowered.
This work opens the possibility for faster traversal-based query execution over fragmented RDF documents, 
given that the data provider uses hypermedia descriptions to characterize the fragmentation
in a structured manner. 
In future work, we will investigate filter-based link pruning for more expressive filter expressions,
and evaluate the approach more extensively over more diverse datasets and queries, and compare our approach with alternative query interfaces.</p>

      </div>
</section>

</main>

<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-642-41338-4_18" typeof="schema:Article">Buil-Aranda, C., Hogan, A., Umbrich, J., Vandenbussche, P.-Y.: SPARQL Web-Querying Infrastructure: Ready for Action? In: Proceedings of the 12th International Semantic Web Conference - Part II. pp. 277–293. Springer-Verlag, Berlin, Heidelberg (2013). doi:10.1007/978-3-642-41338-4_18</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="#Verborgh2016TriplePF" typeof="schema:Article">Verborgh, R., Sande, M.V., Hartig, O., Herwegen, J.V., Vocht, L.D., Meester, B.D., Haesendonck, G., Colpaert, P.: Triple Pattern Fragments: A low-cost knowledge graph interface for the Web. J. Web Semant.</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="https://dx.doi.org/10.1145/3442381.3449911" typeof="schema:Article">Azzam, A., Aebeloe, C., Montoya, G., Keles, I., Polleres, A., Hose, K.: WiseKG: Balanced Access to Web Knowledge Graphs. In: Proceedings of the Web Conference 2021. pp. 1422–1434. Association for Computing Machinery, New York, NY, USA (2021). doi:10.1145/3442381.3449911</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="#ColpaertMaterializedTREE" typeof="schema:Article">Colpaert, P.: Building materializable querying interfaces with the TREE hypermedia specification.</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#lancker2021LDS" typeof="schema:Article">Publishing base registries as Linked Data Event Streams. Proceedings of the 21th International Conference on Web Engineering.</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="#thomasFieldingPhdThesis" typeof="schema:Thesis">Fielding, R.T.: Architectural Styles and the Design of Network-based Software Architectures</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="#Hartig2016" typeof="schema:Article">Hartig, O., Özsu, M.T.: Walking Without a Map: Ranking-Based Traversal for Querying Linked Data. In: Groth, P., Simperl, E., Gray, A., Sabou, M., Krötzsch, M., Lecue, F., Flöck, F., and Gil, Y. (eds.) The Semantic Web – ISWC 2016. Springer International Publishing</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="https://comunica.github.io/Article-ISWC2023-SolidQuery/" typeof="schema:Article">Taelman, R., Verborgh, R.: Link Traversal Query Processing over Decentralized Environments with Structural Assumptions. In: Proceedings of the 22nd International Semantic Web Conference (2023).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="#dahcc_resource" typeof="schema:Article">Bram Steenwinckel, Mathias De Brouwer, Marija Stojchevska, Jeroen Van Der Donckt, Jelle Nelis, Joeri Ruyssinck, Joachim van der Herten, Koen Casier, Jan Van Ooteghem, Pieter Crombez, Filip De Turck, Sofie Van Hoecke and Femke Ongenae: Data Analytics For Health and Connected Care: Ontology, Knowledge Graph and Applications. In: Published in the proceedings of the sixteenth EAI Pervasive Healthcare conference (2022).</dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="#hartig2012" typeof="schema:Article">Hartig, O., Freytag, J.-C.: Foundations of Traversal Based Query Execution over Linked Data. In: Conference on Hypertext and Social Media. ACM</dd>
  <dt id="ref-11">[11]</dt>
  <dd resource="#verborgh2020" typeof="schema:CreativeWork">Verborgh, R., Taelman, R.: Guided Link-Traversal-Based Query Processing</dd>
  <dt id="ref-12">[12]</dt>
  <dd resource="https://comunica.github.io/Article-ISWC2018-Resource/" typeof="schema:Article">Taelman, R., Van Herwegen, J., Vander Sande, M., Verborgh, R.: Comunica: a Modular SPARQL Query Engine for the Web. In: Proceedings of the 17th International Semantic Web Conference (2018).</dd>
</dl>
</section>
</footer>



</div>

</body>
</html>
