<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Filter pushdown as a mecanism for source selection in SPARQL Link Traversal Query processing</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" media="all"    href="styles/katex.css" />
  <meta name="citation_title" content="Filter pushdown as a mecanism for source selection in SPARQL Link Traversal Query processing">
  <meta name="citation_author" content="Bryan-Elliott Tam" />
  <meta name="citation_author" content="Ruben Taelman" />
  <meta name="citation_author" content="Pieter Colpaert" />
  
  <meta name="citation_publication_date" content="2023/07/14" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <!-- Guided Link Traversal Query Processing over RDF documents fragmented with TREE -->
<header>
  <h1 id="filter-pushdown-as-a-mecanism-for-source-selection-in-sparql-link-traversal-query-processing">Filter pushdown as a mecanism for source selection in SPARQL Link Traversal Query processing</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://github.com/constraintAutomaton" typeof="foaf:Person schema:Person" resource="">Bryan-Elliott Tam</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="http://www.rubensworks.net/" typeof="foaf:Person schema:Person" resource="http://www.rubensworks.net/#me">Ruben Taelman</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://pietercolpaert.be/" typeof="foaf:Person schema:Person" resource="https://pietercolpaert.be/#me">Pieter Colpaert</a></li>
  </ul>

  <ul id="affiliations">
    <li id="myaffiliation">IDLab, Department of Electronics and Information Systems, Ghent University – imec</li>
  </ul>

</header>
<!-- Hack to make our custom fonts load in print-mode -->
<!-- https://stackoverflow.com/questions/39364259/chrome-print-preview-doesnt-load-media-only-print-font-face -->
<p><span class="printfont1"> </span>
<span class="printfont2"> </span>
<span class="printfont3"> </span>
<span class="printfont4"> </span></p>

<div id="content">
  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context      -->

      <!-- Need         -->

      <!-- Task         -->

      <!-- Object       -->

      <!-- Findings     -->

      <!-- Conclusion   -->

    </div>
</section>

<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Introduction</h2>

        <p><a href="https://lod-cloud.net/#diagram">In the current years, the web of linked data has grew in size</a>.
To access those data it is necessary to have an interface, the most common is the SPARQL endpoint.
When querying SPARQL endpoints, the interface takes the whole query load and delivers the results to the client,
which causes high workloads and is partially the reason that <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1007/978-3-642-41338-4_18"><a href="https://doi.org/10.1007/978-3-642-41338-4_18">historically they had a low
availability</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>.
Academics have made efforts to introduce linked data publication methods to make the client participate in the query execution,
with the aim to diminish the workloads of the server and still have fast query execution to the client <span class="references">[<a href="#ref-2">2</a>, <a href="#ref-3">3</a>]</span>.
The TREE specification is an effort in that direction <span class="references">[<a href="#ref-4">4</a>, <a href="#ref-5">5</a>]</span>,
that introduces the concept of domain-related fragmentation of large RDF datasets.
This line of research aims to fragment what would be a data dump in a way that client can easily fetch a subset of it to answer their query fully.
The data inside a fragment are bounded with constraints that are expressed using hypermedia description <span class="references">[<a href="#ref-6">6</a>]</span>.
More precisely inside a fragment there is a description of the constraint of the data of the other fragments accessible for this location
in web space.
Because there is no centralized index in those documents Link Traversal Query Processing (LTQP) <span class="references">[<a href="#ref-7">7</a>]</span>,
inspired techniques are used to answer queries. 
This consist in starting with a small set of URL that provided the first data sources and dereferencing recursively 
the IRI present inside the data source to obtain new data sources <span class="references">[<a href="#ref-7">7</a>]</span>. 
In the current state of affairs, it is not possible to use SPARQL to query those documents efficiently because there are no method, to
skip fragments that do not contain data pertaining to the answer to a query.
It result that custom solutions has been created to make use of this data.
The aim of this work is not to introduce the TREE specification but to propose a pushdown filter method with the use of  structural assumption <span class="references">[<a href="#ref-8">8</a>]</span>
to diminish the query execution time by using the SPARQL filter expression has link discrimant.</p>

        <p>One idiomatic use case of fragmented dataset is the publication of sensor data, hence in this paper
we consider the example of <a href="#example-sparql">Listing 1</a> using the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://dahcc.idlab.ugent.be">DAHCC</a> <span class="references">[<a href="#ref-9">9</a>]</span> dataset.
We make queries to get the measure of a specific interval (the metavariable <code>{:filter_expression}</code>)
and information about the sensor using a metadata file that is available online at
<a href="">https:/​/​github.com/predict-idlab/DAHCC-Sources/blob/main/instantiated_examples/_Homelab.owl</a> 
(we adapt the file by deleting the named graph and we use the metavariable<code>{:property}</code> to accommodate the dataset).</p>

        <div class="sidebysidecontainer" style="align-items: stretch !important; ">
<figure id="example-sparql" class="listing" style="padding-right: 5px; padding-left: 5px; height='100%'">
<pre><code>PREFIX sosa: &lt;http://www.w3.org/ns/sosa/&gt; 
</code><code>PREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; 
</code><code>PREFIX wgs: &lt;http://www.w3.org/2003/01/geo/wgs84_pos#&gt;
</code><code>PREFIX etsi: &lt;https://saref.etsi.org/core/&gt;
</code><code>PREFIX dahcc: &lt;https://dahcc.idlab.ugent.be/Ontology/Sensors/&gt;
</code><code>PREFIX saref: &lt;https://saref.etsi.org/core/&gt;
</code><code>
</code><code>SELECT * WHERE {
</code><code>  ?s etsi:hasTimestamp ?t.
</code><code>  ?s etsi:hasValue ?result.
</code><code>  ?s etsi:measurementMadeBy ?sensor.
</code><code>  ?sensor dahcc:analyseStateOf ?stateOf.
</code><code>  ?sensor saref:measuresProperty {:property}
</code><code>  
</code><code>  FILTER({:filter_expression})
</code><code>}</code></pre>
<figcaption>
              <p><span class="label">Listing 1:</span> SPARQL query to get sensor measurement and the information about the sensor</p>
            </figcaption>
</figure>

<figure id="TREE-relation-turtle-example" class="listing" style="padding-right: 5px; padding-left: 5px">
<pre><code>@prefix tree: &lt;https://w3id.org/tree#&gt; .
</code><code>@prefix sosa: &lt;http://www.w3.org/ns/sosa/&gt; .
</code><code>@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .
</code><code>@prefix ex: &lt;https://example.be/&gt; .
</code><code>@prefix etsi: &lt;https://saref.etsi.org/core/&gt;
</code><code>
</code><code>ex:node tree:relation _:b1 .
</code><code>_:b1 a  tree:GreaterThanOrEqualToRelation ;
</code><code>    tree:node ex:nextNode ;
</code><code>    tree:value &quot;2022-01-03T09:47:59.000000&quot;^^xsd:dateTime ;
</code><code>    tree:path etsi:hasTimestamp ;
</code></pre>
<figcaption>
              <p><span class="label">Listing 2:</span> The example is showing a set of triples representing a TREE relation. 
The relation can be converted into the following boolean equation 
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>&gt;</mo><mo>=</mo><mtext>2022-01-03T09:47:59.000000</mtext></mrow><annotation encoding="application/x-tex">x &gt;= \text{2022-01-03T09:47:59.000000}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">2022-01-03T09:47:59.000000</span></span></span></span></span> 
where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> is any variable inside the client SPARQL query that as the predicate <code>etsi:hasTimestamp</code>.</p>
            </figcaption>
</figure>
</div>

        <p>The following section will present our approach and early evaluation.</p>
      </div>
</section>

  <section id="guided_link_traversal" inlist="" rel="schema:hasPart" resource="#guided_link_traversal">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Filter pushdown to discriminate link during LTQP</h2>

        <p>LTQP in its most naive form has a pseudo-infinite domain <span class="references">[<a href="#ref-7">7</a>]</span>, as a result
it is not possible to evaluate the completeness and to have a stopping condition related to the finding of complete results <span class="references">[<a href="#ref-10">10</a>]</span>. 
Also, given the vastness of the web, the overwhelming majority of data sources will not contribute to query completeness (in most realistic queries).
Hartig and Freytag <span class="references">[<a href="#ref-10">10</a>]</span> introduces the concept of reachability criterium, which consists of policies
of IRI to dereference, hence limiting the range of the web that has to be explored to consider to have obtained completeness.
Corrolary, those criteriums serve as a mechanism to prune links that are not relevant to the answer to the query.
This is particularly useful in the context of structured environments such as in the use case of Solid and fragmented datasets
where a priori we have metaknowledge of how to access data related to a query <span class="references">[<a href="#ref-8">8</a>]</span>.
With this metaknowledge, the query engine can find triples that will describe the location of the information requested,
hence “guiding” the query engine towards the right data source <span class="references">[<a href="#ref-11">11</a>]</span>.</p>

        <p>Our pushdown filter is based in its use on the concept of reachability criterium.
In the definition by Hartig and Freytag <span class="references">[<a href="#ref-10">10</a>]</span> a reachability criterium is a function discriminating the dereferencing of 
an IRI based on the triple available in a current document a query.
In our approach, we interpret the hypermedia description of the constraint of the fragment as a boolean equation as
exemplify in <a href="#example-sparql">Listing 1</a>.
In this example, the left hand of the expression, the variable, is contingent on a SPARQL query expression.
It is the variable pertaining to the property that the constraint is targeting.
The property targeted by the relation is defined by the object of the triple having the predicate <code>tree:path</code>.
In the example it was <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">?</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">?t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mclose">?</span><span class="mord mathnormal">t</span></span></span></span>, because the example of <a href="#TREE-relation-turtle-example">Listing 2</a>
has the <code>tree:path</code> property <code>etsi:hasTimestamp</code>. 
The boolean operator such as; equal, greater than, is described by the <a href="https://treecg.github.io/specification/#Relation">RDF type of the TREE relation</a>, in Turtle serialization it is the object of the triple with the predicate “<code>a</code>”.
Finally, the literal is simply represented by the object of the triple in the relation,
containing the predicate <code>tree:value</code>.
The SPARQL filter expression can naively be converted into a boolean expression.
Hence upon discovery of a document, the query engine gathers the relevant triples to form the boolean expression 
representing the constraint of the next fragment and pushdown the SPARQL filter expression.
After having those two boolean expressions close together they are evaluated to find the satisfiability and upon satisfaction
the IRI targeting the next fragment (<code>tree:node</code> in the TREE specification) is added to the link queue following the
concept of reachability criterium.</p>

        <p>We made an open-source implementation of this criterium available at <a href="">https:/​/​github.com/constraintAutomaton/comunica-feature-link-traversal/tree/feature/time-filtering-tree-sparqlee-implementation</a> with an associated demo available at
<a href="">https:/​/​github.com/constraintAutomaton/TREE-Solver-LTQP-demo-engine</a>. In the rest of this section, we will present our experimental result.
We ran four queries derived from the template of <a href="#example-sparql">Listing 1</a> available at 
<a href="">https:/​/​github.com/constraintAutomaton/How-TREE-hypermedia-can-speed-up-Link-Traversal-based-Query-Processing-queries/tree/main/content/code</a> 
with three configurations of the DAHCC participant 31 dataset (of 487 MB) and a timeout of two minutes. 
The first one is a single endpoint query of the data dump. 
For the second and the third configuration we convert the data dump into a 
fragmented dataset following the TREE specification with a one-ary tree topology with 100 and 1000 nodes.
the second configuration uses  a reachability criterium where we follow each link of the fragmented dataset and the third one with the 
pushdown filter approach. As shown in {{:todo }} no query were able to be answered by querying the data dump and following every fragment. 
The reason might be because of the size of the dataset to be processed before executing the joining and solution mapping.
For the configurations with a pushdown filter method, we see that the queries with 1000 fragments perform better than
the one with 100 fragments, particularly when the query has one or zero results. In those cases, the query execution time is almost one
order of magnitude lower with the largest number of fragments. 
With Q3 we can see that the percentage of reduction is 32%, this lowering of performance might be caused by the increase by a factor of 17
of HTTP requests. The query Q4 was not able to be answered, with both fragmentations, the cause might be because it covers a far larger range and hence requires more data to be downloaded and more processing time.</p>

        <table>
          <thead>
            <tr>
              <th>Configuration</th>
              <th>Query</th>
              <th>QT (ms)</th>
              <th>NH</th>
              <th>NR</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Data dump</td>
              <td>Q1/Q2/Q3/Q4</td>
              <td>X</td>
              <td>X</td>
              <td>X</td>
            </tr>
            <tr>
              <td>One ary 100/1000 fragments</td>
              <td>Q1/Q2/Q3/Q4</td>
              <td>X</td>
              <td>X</td>
              <td>X</td>
            </tr>
            <tr>
              <td>One ary 100/1000 fragments Filter pushdown</td>
              <td>Q4</td>
              <td>X</td>
              <td>X</td>
              <td>X</td>
            </tr>
            <tr>
              <td>One ary 100 fragments Filter pushdown</td>
              <td>Q1</td>
              <td>8,892</td>
              <td>3</td>
              <td>0</td>
            </tr>
            <tr>
              <td>One ary 100 fragments Filter pushdown</td>
              <td>Q2</td>
              <td>3,541</td>
              <td>3</td>
              <td>1</td>
            </tr>
            <tr>
              <td>One ary 100 fragments Filter pushdown</td>
              <td>Q3</td>
              <td>59,274</td>
              <td>8</td>
              <td>8,166</td>
            </tr>
            <tr>
              <td>One ary 1000 fragments Filter pushdown</td>
              <td>Q1</td>
              <td>1,171</td>
              <td>3</td>
              <td>0</td>
            </tr>
            <tr>
              <td>One ary 1000 fragments Filter pushdown</td>
              <td>Q2</td>
              <td>734</td>
              <td>3</td>
              <td>1</td>
            </tr>
            <tr>
              <td>One ary 1000 fragments Filter pushdown</td>
              <td>Q3</td>
              <td>39,987</td>
              <td>51</td>
              <td>8,166</td>
            </tr>
          </tbody>
        </table>

      </div>
</section>

  <section id="conclusion" inlist="" rel="schema:hasPart" resource="#conclusion">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Conclusion</h2>

        <p>Concluding from our preliminary implementation, a pushdown filter approach to prune links of fragmented RDF documents based on the SPARQL query language performs better than an approach without it and then querying a data dump of approximately haft a gigabyte in size. 
The cause of the gain of performance seems to be the reduction of the processing by downloading of fewer data inside the engine, but the increase of the HTTP request seems to reduce the gain in performance. This implies that there might be a tradeoff between
the size of the fragments and their numbers.</p>

        <p>This work opens the possibility for faster traversal-based query execution over fragmented RDF documents, 
given that the data provider uses hypermedia descriptions to characterize the fragmentation
in a structured manner. 
In future work, we are going to make a more extensive evaluation of solutions and compare it with a SPARQL endpoint and TPF interface.</p>

      </div>
</section>

</main>

<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-642-41338-4_18" typeof="schema:Article">Buil-Aranda, C., Hogan, A., Umbrich, J., Vandenbussche, P.-Y.: SPARQL Web-Querying Infrastructure: Ready for Action? In: Proceedings of the 12th International Semantic Web Conference - Part II. pp. 277–293. Springer-Verlag, Berlin, Heidelberg (2013). doi:10.1007/978-3-642-41338-4_18</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="#Verborgh2016TriplePF" typeof="schema:Article">Verborgh, R., Sande, M.V., Hartig, O., Herwegen, J.V., Vocht, L.D., Meester, B.D., Haesendonck, G., Colpaert, P.: Triple Pattern Fragments: A low-cost knowledge graph interface for the Web. J. Web Semant.</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="https://dx.doi.org/10.1145/3442381.3449911" typeof="schema:Article">Azzam, A., Aebeloe, C., Montoya, G., Keles, I., Polleres, A., Hose, K.: WiseKG: Balanced Access to Web Knowledge Graphs. In: Proceedings of the Web Conference 2021. pp. 1422–1434. Association for Computing Machinery, New York, NY, USA (2021). doi:10.1145/3442381.3449911</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="#ColpaertMaterializedTREE" typeof="schema:Article">Colpaert, P.: Building materializable querying interfaces with the TREE hypermedia specification.</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#lancker2021LDS" typeof="schema:Article">Publishing base registries as Linked Data Event Streams. Proceedings of the 21th International Conference on Web Engineering.</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="#thomasFieldingPhdThesis" typeof="schema:Thesis">Fielding, R.T.: Architectural Styles and the Design of Network-based Software Architectures</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="#Hartig2016" typeof="schema:Article">Hartig, O., Özsu, M.T.: Walking Without a Map: Ranking-Based Traversal for Querying Linked Data. In: Groth, P., Simperl, E., Gray, A., Sabou, M., Krötzsch, M., Lecue, F., Flöck, F., and Gil, Y. (eds.) The Semantic Web – ISWC 2016. Springer International Publishing</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="https://comunica.github.io/Article-ISWC2023-SolidQuery/" typeof="schema:Article">Taelman, R., Verborgh, R.: Link Traversal Query Processing over Decentralized Environments with Structural Assumptions. In: Proceedings of the 22nd International Semantic Web Conference (2023).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="https://dahcc.idlab.ugent.be" typeof="schema:Article">Bram Steenwinckel, Mathias De Brouwer, Marija Stojchevska, Jeroen Van Der Donckt, Jelle Nelis, Joeri Ruyssinck, Joachim van der Herten, Koen Casier, Jan Van Ooteghem, Pieter Crombez, Filip De Turck, Sofie Van Hoecke and Femke Ongenae: Data Analytics For Health and Connected Care: Ontology, Knowledge Graph and Applications. In: Published in the proceedings of the sixteenth EAI Pervasive Healthcare conference. Springer (2022).</dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="#hartig2012" typeof="schema:Article">Hartig, O., Freytag, J.-C.: Foundations of Traversal Based Query Execution over Linked Data. In: Conference on Hypertext and Social Media. ACM</dd>
  <dt id="ref-11">[11]</dt>
  <dd resource="#verborgh2020" typeof="schema:CreativeWork">Verborgh, R., Taelman, R.: Guided Link-Traversal-Based Query Processing</dd>
</dl>
</section>
</footer>



</div>

</body>
</html>
